---
title: "HW3 - Data wrangling and simple modeling with R"
author: "misken"
date: "October 15, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Step 1 - Familiarize yourself with the data and the assignment

In this assignment you'll do some exploratory data analysis
with R on a dataset about airline flights into and out of of Detroit Metropolitan
Airport during January of 2017. See the README.md file (it's just a plain text file with markdown in it) for details about the data file. 

You'll be doing your work right in this R Markdown document to
do some data wrangling, analysis and model building as well as to document the
steps you did (and answer some questions I'll throw at you).

You'll notice a few "Hacker Extra" tasks
thrown in at the end. These are for those of you who want to go a little above and beyond
and attempt some more challenging tasks. And, feel free to do a some free form
Hacker Extra style work yourself - in other words, do something beyond what
was asked. You'll learn more.

## Step 2 - Create a new R Markdown document

Save this R Markdown document with a new name - name it **HW3_wrangling_lm_[_your last name_].Rmd**. Mine would
be called **HW3_wrangling_lm_isken.Rmd**. Save it into the same folder as this assignment. 

## Step 3 - Create R project and explore data folder

Create an R project based on the folder containing this file. You'll notice that there is a folder named **data**.
Inside of it you'll find the data file for this assignment - **flights_mi_2017.csv** as well as a few other data files. You'll also find an folder named **images** that contains, well, images.


## Step 4 - Complete the following R tasks and answer questions

Now you'll need to complete the following tasks in R. Just like we did in class, you should
use a combination of markdown text (be concise, no need to write tons of text) 
to explain what you are doing and R code chunks to actually do it.
When you are done, use the "Knit" button to generate an HTML file from your R Markdown.
You'll be submitting BOTH the completed R Markdown file as well as the generated HTML file. Just like in the previous homework, you'll simply be compressing your entire project folder and uploading that into Moodle.

**HINT: I highly recommend skimming through the entire document before starting.**

Let's load a few libraries we'll need:

```{r}
library(dplyr)
library(ggplot2)
library(stringr)
library(lubridate)
library(readr)
library(tidyr)
library(reshape2)
```


### Problem 1 - Reading the data in a few different ways

Let's read the data into two `data.frames` named `flights1` and `flights2`. In the first
case we'll use the base R `read.csv` function and in the second we'll use the
**readr** function `read_csv`. For both we will use default arguments to start.

```{r read_flights1}
flights1 <- read.csv("data/flights_mi_2017.csv")
flights2 <- read_csv("data/flights_mi_2017.csv")
```

Use the `str` function to check out the structure of both data frames.


```{r flights1_structure}
str(flights1)

```

```{r flights2_structure}
str(flights2)
```

Summarize the differences in the default behavior between the `read.csv` function and
the `read_csv` function with respect to how character variables and date variables
are treated. Note any other differences you see between the two functions.

> Put your answer here...  
"read.csv" read in all of the variables as factors and integers, including the FL_DATE data as a factor.    "read_csv" read in FL_DATE as a date column but read in all of the columns that were factors above as character data.  

Your goal now is to get the data read into a dataframe named `flights` that
eventually has the following data types for each of the columns. You can:

* use either `read.csv` or `read_csv`
* use any argument values you want with either function (i.e. you do NOT need
to just accept the default behavior)
* use additional commands after reading in the data to make any data type changes needed.
* IMPORTANT: If for some reason you simply cannot get the flights dataframe created correctly (but you should, there's nothing tricky), I've included an RDS file in the data/ folder named **flights.rds**. You could simply read it in to a dataframe named flights - `flights <- readRDS("data/flights.rds")`. This is a last resort.

Here's the target data types:

  FL_DATE            : Date or POSIXct
  CARRIER            : Factor
  ORIGIN             : Factor
  ORIGIN_CITY_NAME   : Factor
  ORIGIN_STATE_ABR   : Factor
  DEST               : Factor
  DEST_CITY_NAME     : Factor
  DEST_STATE_ABR     : Factor
  CRS_DEP_TIME       : int or num
  DEP_TIME           : int or num
  DEP_DELAY          : int or num
  TAXI_OUT           : int or num
  WHEELS_OFF         : int or num
  WHEELS_ON          : int or num
  TAXI_IN            : int or num
  CRS_ARR_TIME       : int or num
  ARR_TIME           : int or num
  ARR_DELAY          : int or num
  CANCELLED          : int or num
  CANCELLATION_CODE  : Factor
  CRS_ELAPSED_TIME   : int or num
  ACTUAL_ELAPSED_TIME: int or num
  AIR_TIME           : int or num
  DISTANCE           : int or num

After you have the `flights` dataframe created, remove `flights1` and `flights2`.

```{r read_flights}
## Read in the csv file
flights <- as.data.frame(flights1)

## Do any data type conversions needed
flights$FL_DATE <- as.POSIXct(flights$FL_DATE)

## Remove flights1 and flights2 from the workspace
rm(flights1, flights2)

## Check out the structure of your flights dataframe
str(flights)
```

### Problem 2 - Flights into and out of DTW

Use **dplyr** for all of the questions in this problem.

Find the number of flights into DTW by origin airport. Display the results in descending order by number of flights.

```{r flights_by_origin}
flights %>%
  filter(DEST == "DTW") %>%
  group_by(ORIGIN) %>%
  summarize(num_flights = n()) %>%
  arrange(desc(num_flights))
```

Now use **dplyr** to compute the following summary statistics for ARR_DELAY, grouped by origin airport, for flights into DTW. We did this in the **dplyr** notes.

* number of flights 
* mean and median
* min, max, 5th and 95th percentile
* IQR, standard deviation, range

```{r stats_by_origin}
flights %>%
  filter(DEST == "DTW") %>%
  group_by(ORIGIN) %>%
  summarize(num_flights = n(),
          mean_arr_delay = mean(ARR_DELAY, na.rm = TRUE),
          median_arr_delay = median(ARR_DELAY,  na.rm = TRUE),
          min_arr_delay = min(ARR_DELAY, na.rm = TRUE),
          max_arr_delay = max(ARR_DELAY, na.rm = TRUE),
          p5_arr_delay = quantile(ARR_DELAY, 0.05, na.rm = TRUE),
          p95_arr_delay = quantile(ARR_DELAY, 0.95, na.rm = TRUE),
          iqr_arr_delay = IQR(ARR_DELAY, na.rm = TRUE),
          sdev_arr_delay = sd(ARR_DELAY, na.rm = TRUE),
          range_arr_delay = max(ARR_DELAY, na.rm = TRUE) - min(ARR_DELAY, na.rm = TRUE))

```


Repeat the above query but just include origin airports for which there were at least 100 flights.

```{r stats_by_origin_gt100}
flights %>%
  filter(DEST == "DTW") %>%
  group_by(ORIGIN) %>%
  filter(n() > 100) %>%
  summarize(num_flights = n(),
          mean_arr_delay = mean(ARR_DELAY, na.rm = TRUE),
          median_arr_delay = median(ARR_DELAY,  na.rm = TRUE),
          min_arr_delay = min(ARR_DELAY, na.rm = TRUE),
          max_arr_delay = max(ARR_DELAY, na.rm = TRUE),
          p5_arr_delay = quantile(ARR_DELAY, 0.05, na.rm = TRUE),
          p95_arr_delay = quantile(ARR_DELAY, 0.95, na.rm = TRUE),
          iqr_arr_delay = IQR(ARR_DELAY, na.rm = TRUE),
          sdev_arr_delay = sd(ARR_DELAY, na.rm = TRUE),
          range_arr_delay = max(ARR_DELAY, na.rm = TRUE) - min(ARR_DELAY, na.rm = TRUE))
```

Now for something more challenging.

You start to wonder about the difference between the number of flights
into DTW from a particular airport and the number of flights out of DTW for
that same airport. For example, consider ATL:

```{r inout_ATL}
num_in_ATL <- flights %>% 
  filter(ORIGIN == 'ATL') %>% 
  summarize(num_flights = n())

num_out_ATL <- flights %>% 
  filter(DEST == 'ATL') %>% 
  summarize(num_flights = n()) 

# Convert resulting single valued dataframe to a number 
num_in_ATL <- as.numeric(num_in_ATL)
num_out_ATL <- as.numeric(num_out_ATL)

sprintf("Num in to ATL = %i, Num out of ATL = %i", num_in_ATL, num_out_ATL)
```

BTW, instead of using `as.numeric` above to convert the result from
a dataframe into a number, we could also use the `pull()` function in
our **dplyr** statement.

```{r inout_ATL_pull}
num_out_ATL <- flights %>% 
  filter(DEST == 'ATL') %>% 
  summarize(num_flights = n()) %>% 
  pull()

```

Of course we don't want to do this just for one airport and we certainly
don't way to repeat the above approach for each airport. This is where R really shines in that we can design a multistep workflow that does
something a little more difficult.

We want to do the following.

* Create a dataframe named `num_in` that counts flights by ORIGIN (don't include 'DTW' as an ORIGIN).
* Create a dataframe named `num_out` that counts flights by DEST (again, don't include 'DTW' as a DEST).
* Use one of **dplyr**'s `*_join` commands to join the two dataframes
together by ORIGIN = DEST, creating a new dataframe named `inout`.
* Rename the columns in `inout` using the vector c("AIRPORT", "num_in", "num_out")
* Replace any NAs in `inout` with 0.
* Compute a new column in `inout` called `balance` that is `num_in - num_out`
* Display `inout` sorted in descending order by balance to see which airports have the greatest discrepancy between number of flights into DTW and number of flights from DTW.

```{r num_in_num_out_soln}
# Of course you already did queries similar to these up above
#
num_in <-
flights %>%
  filter(ORIGIN != "DTW") %>%
  group_by(ORIGIN) %>%
  summarize(num_flights = n())
# 
num_out <- flights %>% 
  filter(DEST != "DTW") %>%
  group_by(DEST) %>%
  summarize(num_flights = n())
```


```{r merge_inout_soln}
# Join the num_in and num_out dataframes  ORIGIN = DEST
inout <- full_join(num_in, num_out, by = c('ORIGIN' = 'DEST'))

## Rename columns in new inout dataframe
names(inout) <- c("AIRPORT", "num_in", "num_out")

## Replace NA values in the num_in, num_out with 0.
# https://stackoverflow.com/questions/8161836/how-do-i-replace-na-values-with-zeros-in-an-r-dataframe

inout[is.na(inout)] <- 0

## Compute difference between number of flights in and number out
inout$balance <- inout$num_in - inout$num_out

  
## Display sorted descending by balance and num_out
inout %>%
  arrange(desc(balance), desc(num_out))

```


### Problem 3 - converting wide to long data to facilitate plotting


You decide you want to create a bar plot showing the total number of flights by hour of day and day of week. One of your colleagues, trying to be helpful, creates a file for you named **dow_hour_summary.csv**. However, the file they created was based on January 2016 data. Let's read it in.

```{r read_dow_hour_summary_csv}
dow_hour_summary_2016 <- read_csv("data/dow_hour_summary.csv")
```

Uh oh. The data is in "wide format". You want to facet by day of week but those are the column headings. Use either the **reshape2** or **tidyr** package to convert this data into long format and then create a bar chart showing the total number of flights by hour of day and faceted by day of week.

```{r reshape}
# added library(reshape2) where we loaded the other libraries up top

dow_hour_summary_2016_long <- melt(dow_hour_summary_2016, id.vars = c("CRS_DEP_HOUR"),
                                   variable.name = "day_of_week", value.name = "flights")

head(dow_hour_summary_2016_long)

```

```{r plot_reshaped}
 ggplot(dow_hour_summary_2016_long, aes(x=CRS_DEP_HOUR, y=flights)) +
   geom_bar(stat="identity", colour="black", fill="blue") +
   labs(title = "Flights per Hour by Day of Week") +
   xlab("Hour of Day") +
   ylab("Number of flights") +
   facet_wrap(~day_of_week)
```

For the rest of the problems we are just interested in flights **out** of DTW. To make our life a little easier, let's create a dataframe called `flights_out`.

```{r flights_out}
flights_out <- flights %>% 
  filter(ORIGIN == 'DTW')
```

### Problem 4 - Engineer new features to facilitate time of day analysis

Remember, use the new `flights_out` dataframe for the rest of
the assignment unless otherwise specified.

Create a new field showing the hour of day for the flight departure called CRS_DEP_HOUR based on CRS_DEP_TIME.
Check it by displaying the first 10 rows and the CRS_DEP_HOUR and
CRS_DEP_TIME fields. Use can use **dplyr** and its `mutate()` function
for this problem or you can use base R commands. Even better, show
how to do it both ways. HINT: We did this in class.

```{r crs_dep_hour}
## Add new departure hour field

flights_out$CRS_DEP_HOUR <- flights_out$CRS_DEP_TIME %/% 100

## or using mutate...
mutate(flights_out, CRS_DEP_HOUR_2 = CRS_DEP_TIME %/% 100) %>%
  head(10)

## Display first 10 rows and just the CRS_DEP_HOUR and CRS_DEP_TIME fields
# flights_out[???, ???]
flights_out %>% select(CRS_DEP_HOUR, CRS_DEP_TIME) %>%
  head(10)  


```

In addition, you decide that you'd like to create a "coarser" version 
based on "departure period". Let's call it CRS_DEP_PRD. The values 
of this new variable are as follows:

1 if CRS_DEP_HOUR in [0,5]
2 if CRS_DEP_HOUR in [6,12]
3 if CRS_DEP_HOUR in [13,18]
4 if CRS_DEP_HOUR in [19,23]


See http://www.cookbook-r.com/Manipulating_data/Recoding_data/ for ideas. After
creating the departure period field, makes sure you convert it to a factor if
it's not already. HINT: The `cut()` function is useful.

```{r crs_dep_prd}
# By default, the ranges are open on the left, and closed (includes cut point) on the right 
# To set it so that ranges are closed on the left and open on the right, like [7,9), use right=FALSE

flights_out$CRS_DEP_PRD <- cut(flights_out$CRS_DEP_HOUR,
                     breaks=c(0, 5, 12, 18, 23),
                     labels=c("0-5","6-12","13-18","19-23"))
# Did it work?
flights_out %>% select(CRS_DEP_HOUR, CRS_DEP_PRD) %>%
  head(10) 

# yep :) ... and as a bonus CRS_DEP_PRD is already a factor

```


Finally, create a field FL_DOW based on FL_DATE representing the day of week
of the flight. The **lubridate** package will be helpful. 

```{r fl_dow}
# Create day of week field called FL_DOW 
flights_out$FL_DOW <- wday(ymd(flights_out$FL_DATE), label = TRUE, abbr = FALSE)

# Did it work?
flights_out %>% select(FL_DATE, FL_DOW) %>%
  head(10) 
flights_out %>% select(FL_DATE, FL_DOW) %>%
  tail(10) 

# Hooray!
```

### Problem 5 - Do group by analysis on CRS_DEP_PRD

Are departure delays related to departure period? Start by computing basic summary statistics for DEP_DELAY by CRS_DEP_PRD. Of course you already know how to do this from previous questions in this assignment. If you weren't able to create CRS_DEP_PRD, then use CRS_DEP_HOUR.

Use **dplyr**.

```{r}

ddelay_period_summary <- flights_out %>%
  group_by(CRS_DEP_PRD) %>%
  summarize(num_flights = n(),
        mean_dep_delay = mean(DEP_DELAY, na.rm = TRUE),
        median_dep_delay = median(DEP_DELAY,  na.rm = TRUE),
        min_dep_delay = min(DEP_DELAY, na.rm = TRUE),
        max_dep_delay = max(DEP_DELAY, na.rm = TRUE),
        p5_dep_delay = quantile(DEP_DELAY, 0.05, na.rm = TRUE),
        p95_dep_delay = quantile(DEP_DELAY, 0.95, na.rm = TRUE),
        iqr_dep_delay = IQR(DEP_DELAY, na.rm = TRUE),
        sdev_dep_delay = sd(DEP_DELAY, na.rm = TRUE),
        range_dep_delay = max(DEP_DELAY, na.rm = TRUE) - min(DEP_DELAY, na.rm = TRUE))

head(ddelay_period_summary)
# tail(ddelay_period_summary) - Do not need a head & a tail. There are only 4 categories
```

> Your interepretation here ...  
There are fewer (by a lot) flights departing from DTW in the 0-5 hours.  Flights out spike in the 6-12 hours and then decrease for the rest of the day.  The mean delay increases as the day goes on, although the median delay for all time segments is a negative number indicating an early departure. The 5th & 95th %'s of delay also increase but not as drastically as the original mean statistic might have alluded to.  This could indicate that there is some outlier data pulling our means up.  Standard deviation and range are also increased with the later time ranges.   

**Hacker Extra** If you'd like, make boxplots or violin plots of DEP_DELAY by
CRS_DEP_PRD. They won't be pretty. Make them easier to read.

```{r}

ggplot(flights_out, aes(y=DEP_DELAY, x=CRS_DEP_PRD)) + 
  geom_violin(na.rm = TRUE) +
  
  # The following trims the data to that included within the 10th & 90th percentile to deal with outlier issue
  scale_y_continuous(limits = quantile(flights_out$DEP_DELAY, c(0.1, 0.9), na.rm = TRUE)) +
  
  # The following adds a point on each violin plot which shows the mean
  stat_summary(fun.y=mean, geom="point", size=2, color="red") +
  geom_text(stat = 'summary', fun.y=mean, aes(label = round(..y.., 2)), nudge_x = 0.1, hjust = 0) +
  
  #titles/labels...
  labs(title = "HACKER EXTRA - Departure Delays out of DTW by Segmented Hours (trimmed)") +
  ylab("Delay in Minutes") +
  xlab("Hour Range")
```

### Problem 6 - A scatterplot of DEP_DELAY by CRS_DEP_HOUR

Create two versions, a standard scatter plot and one with "jitter". 

Jitter is useful when you have many duplicate points that obscure each other.

```{r scatter_delay_hour_soln}
ggplot(flights_out) +
  geom_point(aes(y=DEP_DELAY, x=CRS_DEP_HOUR, color = "red")) + 
  ggtitle("Departure Delays out of DTW by Hour - no jitter") +
  ylab("Delay in Minutes") +
  xlab("Hour") 
# 
ggplot(flights_out) +
  geom_point(aes(y=DEP_DELAY, jitter(x=CRS_DEP_HOUR), color = "red")) + 
  ggtitle("Departure Delays out of DTW by Hour - with jitter") +
  ylab("Delay in Minutes") +
  xlab("Hour")
```

### Problem 7 - Are departure delays related to day of week? 

Use plots and/or group by analysis to take a first look at these questions.

```{r dow_effect}
flights_out %>%
  filter(DEP_DELAY > 0) %>%
  ggplot(aes(x=FL_DOW, y=DEP_DELAY)) +
  geom_bar(stat="identity", fill="blue") +
  labs(title = "DTW Departure Number of Delays by Day of Week") +
  ylab("Number of Departure Delays") +
  xlab("Day of Week")

# Now calculate delays as a percentage of the number of flights that go out on each day
#There is probably an easier way to do this... but I'm goin with what I know how to do ;)

#summarize tot flights per day
tot_flights <- flights_out %>%
  group_by(FL_DOW) %>%
  summarize(tot_num_flights = n())
#Summarize delayed flights by day
del_flights <- flights_out %>%
  group_by(FL_DOW) %>%
  filter(DEP_DELAY > 0) %>%
  summarize(del_num_flights = n())
#join the two and calculate delays as a percentage of flights
percent_del <- full_join(tot_flights, del_flights, by = c('FL_DOW' = 'FL_DOW')) %>%
  mutate(per_del = del_num_flights / tot_num_flights) 
#percent_del

#Lets look at the total number of flights per day...
percent_del %>%
  ggplot(aes(x=FL_DOW, y=tot_num_flights)) +
  geom_bar(stat="identity", fill="blue") +
  labs(title = "DTW Flights by Day of Week") +
  ylab("Daily Departures") +
  xlab("Day of Week") 

# make a pretty graph of Departure %'s
percent_del %>%
  ggplot(aes(x=FL_DOW, y=per_del)) +
  geom_bar(stat="identity", fill="blue") +
  labs(title = "DTW Departure % of Flights Delayed by Day of Week") +
  ylab("Daily Departure Delay %") +
  xlab("Day of Week") +
  geom_text(aes(x = FL_DOW, 
  y = per_del + 0.05, label = round(per_del, 2)))

#When calculated as a percentage of flights the days are more similar than at first glance
```
> At first glance it seems like the day of the week has an impact on flight delays.  Graphing the number of flights shows that Sunday has way more delays than any of the other days, with Monday and Tuesday nearly tying for second.  However, if you take into account the total number of flights on each day the picture is not as drastic.  Sunday still has the most delays, at around 40% of flights, but the other days are not as different as they originally seemed.  Wednesday seems to be the best day of the week to avoid delays as only 27% of flights are delayed on that day.

### Problem 8 - Linear regression models

Given the limited number of fields we have and the fact that we only have one month of data, do you think we can build a linear regression model to predict DEP_DELAY that outperforms a simple null model which simply predicts the overall mean departure delay?

I'll partition `flights_out` into a training and test set. Use the training data to build your model. Then use your model to make predictions on the test set and compute RMSE for your predictions. Compare to the RMSE I compute below for the naive null model based on just predicting overall mean delay for everyone.

```{r partition}
# Simple partition into train and test set
set.seed(447)
testrecs <- sample(nrow(flights_out), floor(0.20 * nrow(flights_out)))
flights_out_train <- flights_out[-testrecs,]  
flights_out_test <- flights_out[testrecs,]

# Get rid of cancelled flights
flights_out_train <- flights_out_train %>%
  filter(CANCELLED == 0)

flights_out_test <- flights_out_test %>%
  filter(CANCELLED == 0)

```

Create our "null model" which is simply the overall mean DEP_DELAY for all the flights in the training dataset. Think of a null model as a very simple "model" that any other model better be able to beat if it's going to be any good.

```{r null_model}
null_pred <- mean(flights_out_train$DEP_DELAY)
null_pred
```

```{r}
# Load MLmetrics library to get rmse() function
library(MLmetrics)
null_rmse <- RMSE(flights_out_test$DEP_DELAY, null_pred)
null_rmse
```

Try to build a linear regression model to predict DEP_DELAY that has a lower RMSE than this on the test data. Feel free to create any new fields you'd like as long as you don't include information that would not be available the day before the actual flight - i.e. we need to avoid being accidentally "clairvoyant".

```{r mickis linear model}
# possible important variables - CARRIER, DEST, CRS_DEP_TIME v CRS_DEP_HOUR v CRS_DEP_PRD, TAXI_OUT, FL_DOW
#Check for correlation issues
summary(flights_out_train)
#
#Don't see any N/A's in the variables we will use so moving forward...
mickiLM1 <- lm(DEP_DELAY ~ CARRIER + DEST + CRS_DEP_TIME + FL_DOW, data=flights_out_train)
summary(mickiLM1)

# Wow, that's too much.  Let's make new variables out of the CARRIER's that tested at the highest # significance levels and maybe remove DEST

```
```{r mickis additional linear models}
#Make indicator variables for CARRIER's EV & OO 
flights_out_train$EV <- ifelse(flights_out_train$CARRIER == "EV", 1, 0) 
flights_out_train$OO <- ifelse(flights_out_train$CARRIER == "OO", 1, 0) 
#head(flights_out_train) 

mickiLM2 <- lm(DEP_DELAY ~ EV + OO + CRS_DEP_TIME + FL_DOW, data=flights_out_train)
summary(mickiLM2)

mickiLM3 <- lm(DEP_DELAY ~ EV + OO + CRS_DEP_HOUR + FL_DOW, data=flights_out_train)
summary(mickiLM3)

mickiLM4 <- lm(DEP_DELAY ~ EV + OO + CRS_DEP_PRD + FL_DOW, data=flights_out_train)
summary(mickiLM4)

mickiLM5 <- lm(DEP_DELAY ~ EV + OO + CRS_DEP_PRD, data=flights_out_train)
summary(mickiLM5)
```
```{r}
#Need to make the test data match the training data
flights_out_test$EV <- ifelse(flights_out_test$CARRIER == "EV", 1, 0) 
flights_out_test$OO <- ifelse(flights_out_test$CARRIER == "OO", 1, 0) 

delPredict2 <- predict(mickiLM2, newdata=flights_out_test)
delPredict3 <- predict(mickiLM3, newdata=flights_out_test)
delPredict4 <- predict(mickiLM4, newdata=flights_out_test)
delPredict5 <- predict(mickiLM5, newdata=flights_out_test)

save(flights_out_train, flights_out_test,
     mickiLM2, mickiLM3, mickiLM4, mickiLM5,
     delPredict2, delPredict3, delPredict4, delPredict5,
     file="data/delPredict2345.rdata")

fit_preds <- data.frame(act_del = flights_out_test[,"DEP_DELAY"],
                          lm2_del = delPredict2,
                          lm3_del = delPredict3,
                          lm4_del = delPredict4,
                          lm5_del = delPredict5)

head(fit_preds)

(RMSE2 <- sqrt(with(fit_preds, sum((act_del - lm2_del)^2))/nrow(fit_preds)))
(RMSE3 <- sqrt(with(fit_preds, sum((act_del - lm3_del)^2))/nrow(fit_preds)))
(RMSE4 <- sqrt(with(fit_preds, sum((act_del - lm4_del)^2))/nrow(fit_preds)))
(RMSE5 <- sqrt(with(fit_preds, sum((act_del - lm5_del)^2))/nrow(fit_preds)))

```
>Well... all four model RMSE's are less than the simple model RMSE.  Not by much though... a good prediction would require some more work

### Problem 9 - Bar charts

Create a basic bar chart based on number of flights by Carrier.

```{r basic_bar}
ggplot(flights_out) + geom_bar(aes(x=CARRIER))
```

Now create a similar plot but instead of the bars being based on
counts, make it be the mean DEP_DELAY. The key is
to base your plot on the result of a **dplyr** query. Hint: You'll
also want to learn about the `stat` layer in ggplots.

This is a general strategy that is often useful for complex charts - create an intermediate dataframe that will make it "easy" to create the chart. Tools like **dplyr** (or **plyr** or **apply** family) are
often a good choice for creating the intermediate dataframe.

For an additional challenge, try to order the bars so longest bars first.

Here's what my solution looks like:

```{r mean_depdelay_carrier}
knitr::include_graphics("images/mean_depdelay_carrier.png")
```


```{r adv_bar}
mean_del_carr <- flights_out %>%
  group_by(CARRIER) %>%
  summarize(DEP_DELAY = (mean(DEP_DELAY, na.rm = TRUE)))
head(mean_del_carr)

mean_del_carr %>%
  ggplot(aes(x=reorder(CARRIER, -DEP_DELAY), y=DEP_DELAY)) +
  geom_bar(stat="identity", fill="blue") +
  labs(title = "DTW Departure Mean Delays by Carrier") +
  ylab("Mean Delay in Minutes") +
  xlab("Carrier") +
  geom_text(aes(x = CARRIER,
  y = DEP_DELAY + .5, label = round(DEP_DELAY, 0)))
```



**Hacker Extra #1 - Faceted density plots for high volume airports**

Create faceted (by ORIGIN) density plots of DEP_DELAY for those airports having greater than 200 flights.

Here's what my solution looks like:

```{r airtime_histos}
knitr::include_graphics("images/depdelay_densities.png")
```


```{r densities_depdelay}

flights %>%
  add_count(ORIGIN) %>%
  filter(n > 200) %>%
  group_by(ORIGIN) %>%
  ggplot(aes(DEP_DELAY)) + geom_density() +
  facet_wrap(~ORIGIN, scales='free_x') +
  labs(title = "HACKER EXTRA - Density Plots of DEP_DELAY for Airports with 200+ flights") 

#Hmmm mine has a few more airports listed than yours.  Better check the counts...
flights %>%
  group_by(ORIGIN) %>%
  summarize(num_flights = n()) %>%
  arrange(desc(num_flights)) %>%
  head(21) 
#I have 20 density plots so I will check to make sure the top 20 of 21 airports listed are 200+ flights

#Looks right to me :)
#Perhaps you filtered out N/A rows's on yours

```



### Hacker Extra -#2 - Average number of flights by day of week by carrier

Compute the average number of flights by day of week by carrier. Be careful - you must make sure that your solution works even if some carrier has a date on which they have no flights. Here's what my solution looks like.

```{r flights_carrier_dow_png}
knitr::include_graphics("images/flights_carrier_dow.png")
```

```{r hacker_extra_2}

# Apologies upfront... this is going to get messy lol
#Add dow column to flights
flights$FL_DOW <- wday(ymd(flights$FL_DATE), label = TRUE, abbr = FALSE) 
  #head(flights)

#From original data
startDate <- min(flights$FL_DATE)
endDate <- max(flights$FL_DATE)

#Now build a sequence between the dates 
allDates <-seq(from = startDate, to = endDate, by = "days")
#head(allDates)

#Create a data frame that counts num of dow for all dates in range
myDF <- data.frame(ALLDATES=allDates) 
myDF$ALLDATES <- as.POSIXct(myDF$ALLDATES)
myDF$FL_DOW <- wday(ymd(myDF$ALLDATES), label = TRUE, abbr = FALSE) 
myDF <- myDF %>%
  group_by(FL_DOW) %>%
  summarize(dow_count = n()) 

mynewtable <- merge(flights, myDF[, c("FL_DOW", "dow_count")], by="FL_DOW")
#head(mynewtable)

#Now, for what we were after...
mynewesttable <- mynewtable %>%
  add_count(CARRIER, FL_DOW) %>%
  mutate(dowabr = substr(FL_DOW, 1, 2)) %>%
  mutate(FlPerDOW = n/dow_count) %>%
  group_by_(.dots=c("CARRIER", "FL_DOW", "dowabr")) %>%
  summarize(avg_flights=mean(FlPerDOW)) 
head(mynewesttable)

#Need to order the abbreviated dow column 
mynewesttable$dowabr <- factor(mynewesttable$dowabr,levels = c("Su", "Mo", "Tu", "We", "Th", "Fr", "Sa"))

mynewesttable %>%
  ggplot(aes(x=dowabr, y=avg_flights)) +
   geom_bar(stat="identity", colour="black", fill="blue") +
   labs(title = "Hacker Extra #2 - Average Flights per Day") +
   xlab("Days of Week") +
   ylab("Average # of Flights") +  
   facet_wrap(~CARRIER, scales='free_x') 

# I eventually got there... but it was an ugly redundant path! That... was a battle
# https://github.com/MickiRhen/hw3_files


```


## Deliverables

Make sure all of your files are closed and saved and are inside your R project folder. Compress that entire folder and upload it via Moodle.